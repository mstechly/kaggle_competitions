{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset generator\n",
    "\n",
    "The main unit of information in this dataset is phrase.\n",
    "Phrase can by anything from the whole sentence to singe word.\n",
    "\n",
    "In order to learn a language model it would be useful to have a dataset consisting of the whole sentences and in the format which is easily used by fastai library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset from rotten tomatoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "RT_PATH = os.path.join('rt_data')\n",
    "IMDB_PATH = os.path.join('imdb_data')\n",
    "FULL_PATH = os.path.join('full_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_train_dataset = pd.read_csv(os.path.join(RT_PATH, 'train.tsv'), sep='\\t')\n",
    "rt_test_dataset = pd.read_csv(os.path.join(RT_PATH, 'test.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_train_dataset = rt_train_dataset.rename(index=str, columns={\" PhraseId\": \"PhraseId\"})\n",
    "rt_test_dataset = rt_test_dataset.rename(index=str, columns={\" PhraseId\": \"PhraseId\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_text_files(dataset, name):\n",
    "    sentences = []\n",
    "    grouped_by_sentence_id = dataset.groupby(\"SentenceId\")\n",
    "    for sentence_id, group in grouped_by_sentence_id:\n",
    "        sentences.append(group.iloc[0].Phrase)\n",
    "        \n",
    "    path = os.path.join(RT_PATH, name)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "        file = open(os.path.join(path, str(idx)+\".txt\"), \"w\")\n",
    "        file.write(sentence)\n",
    "        file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_text_files(rt_train_dataset, \"train\")\n",
    "dataset_to_text_files(rt_test_dataset, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset from rotten tomatoes and IMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are is that much text in the Rotten Tomato dataset, I decided to try to learn language model by adding IMDB model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_train_path = os.path.join(RT_PATH, \"train\")\n",
    "rt_test_path = os.path.join(RT_PATH, \"test\")\n",
    "imdb_train_path = os.path.join(IMDB_PATH, \"train\", \"all\")\n",
    "imdb_test_path = os.path.join(IMDB_PATH, \"test\", \"all\")\n",
    "full_train_path = os.path.join(FULL_PATH, \"train\")\n",
    "full_test_path = os.path.join(FULL_PATH, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(full_train_path, exist_ok=True)\n",
    "os.makedirs(full_test_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_files(source_dir, target_dir):\n",
    "    src_files = os.listdir(source_dir)\n",
    "    for file_name in src_files:\n",
    "        full_file_name = os.path.join(source_dir, file_name)\n",
    "        if (os.path.isfile(full_file_name)):\n",
    "            shutil.copy(full_file_name, target_dir)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_files(rt_train_path, full_train_path)\n",
    "copy_files(rt_test_path, full_test_path)\n",
    "copy_files(imdb_train_path, full_train_path)\n",
    "copy_files(imdb_test_path, full_test_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-fast-ai",
   "language": "python",
   "name": "venv-fast-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
